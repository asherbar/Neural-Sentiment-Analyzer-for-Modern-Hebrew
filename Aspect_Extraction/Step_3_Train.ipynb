{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "from time import time\n",
    "import utils as U\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    # filename='out.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--ortho-reg'], dest='ortho_reg', nargs=None, const=None, default=0.1, type=<class 'float'>, choices=None, help='The weight of orthogonol regularizaiton (default=0.1)', metavar='<float>')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse arguments\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-o\", \"--out-dir\", dest=\"out_dir_path\", type=str, metavar='<str>', default='output',\n",
    "                    help=\"The path to the output directory\")\n",
    "parser.add_argument(\"-e\", \"--embdim\", dest=\"emb_dim\", type=int, metavar='<int>', default=200,\n",
    "                    help=\"Embeddings dimension (default=200)\")\n",
    "parser.add_argument(\"-b\", \"--batch-size\", dest=\"batch_size\", type=int, metavar='<int>', default=50,\n",
    "                    help=\"Batch size (default=50)\")\n",
    "parser.add_argument(\"-v\", \"--vocab-size\", dest=\"vocab_size\", type=int, metavar='<int>', default=2000,\n",
    "                    help=\"Vocab size. '0' means no limit (default=1000)\")\n",
    "parser.add_argument(\"-as\", \"--aspect-size\", dest=\"aspect_size\", type=int, metavar='<int>', default=1,\n",
    "                    help=\"The number of aspects specified by users (default=14)\")\n",
    "parser.add_argument(\"--emb\", dest=\"emb_path\", type=str, metavar='<str>', help=\"The path to the word embeddings file\",default='preprocessed_data/w2v_embedding')\n",
    "parser.add_argument(\"--epochs\", dest=\"epochs\", type=int, metavar='<int>', default=15,\n",
    "                    help=\"Number of epochs (default=15)\")\n",
    "parser.add_argument(\"-n\", \"--neg-size\", dest=\"neg_size\", type=int, metavar='<int>', default=20,\n",
    "                    help=\"Number of negative instances (default=20)\")\n",
    "parser.add_argument(\"--maxlen\", dest=\"maxlen\", type=int, metavar='<int>', default=0,\n",
    "                    help=\"Maximum allowed number of words during training. '0' means no limit (default=0)\")\n",
    "parser.add_argument(\"--seed\", dest=\"seed\", type=int, metavar='<int>', default=1234, help=\"Random seed (default=1234)\")\n",
    "parser.add_argument(\"-a\", \"--algorithm\", dest=\"algorithm\", type=str, metavar='<str>', default='adam',\n",
    "                    help=\"Optimization algorithm (rmsprop|sgd|adagrad|adadelta|adam|adamax) (default=adam)\")\n",
    "parser.add_argument(\"--domain\", dest=\"domain\", type=str, metavar='<str>', default='restaurant',\n",
    "                    help=\"domain of the corpus {restaurant, beer}\")\n",
    "parser.add_argument(\"--ortho-reg\", dest=\"ortho_reg\", type=float, metavar='<float>', default=0.1,\n",
    "                    help=\"The weight of orthogonol regularizaiton (default=0.1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0912 08:36:03.490820  8168 utils.py:142] Arguments:\n",
      "I0912 08:36:03.491819  8168 utils.py:149]   algorithm: adam\n",
      "I0912 08:36:03.492819  8168 utils.py:149]   aspect_size: 1\n",
      "I0912 08:36:03.492819  8168 utils.py:149]   batch_size: 50\n",
      "I0912 08:36:03.493817  8168 utils.py:149]   command: C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py -f C:\\Users\\t15k\\AppData\\Roaming\\jupyter\\runtime\\kernel-80391531-7ea8-4cad-bded-8f3f1e0c1747.json\n",
      "I0912 08:36:03.494818  8168 utils.py:149]   domain: restaurant\n",
      "I0912 08:36:03.495819  8168 utils.py:149]   emb_dim: 200\n",
      "I0912 08:36:03.495819  8168 utils.py:149]   emb_path: preprocessed_data/w2v_embedding\n",
      "I0912 08:36:03.496819  8168 utils.py:149]   epochs: 15\n",
      "I0912 08:36:03.497818  8168 utils.py:149]   maxlen: 0\n",
      "I0912 08:36:03.498819  8168 utils.py:149]   neg_size: 20\n",
      "I0912 08:36:03.498819  8168 utils.py:149]   ortho_reg: 0.1\n",
      "I0912 08:36:03.499819  8168 utils.py:149]   out_dir_path: output\n",
      "I0912 08:36:03.500818  8168 utils.py:149]   seed: 1234\n",
      "I0912 08:36:03.501818  8168 utils.py:149]   vocab_size: 2000\n"
     ]
    }
   ],
   "source": [
    "out_dir = args.out_dir_path \n",
    "U.mkdir_p(out_dir)\n",
    "U.print_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.seed > 0:\n",
    "    np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Creating vocab ...\n",
      "   7710 total words, 1658 unique words\n",
      "  keep the top 2000 words\n",
      " Reading dataset ...\n",
      "  train set\n",
      "   <num> hit rate: 0.00%, <unk> hit rate: 0.00%\n",
      "  test set\n",
      "   <num> hit rate: 0.00%, <unk> hit rate: 11.69%\n"
     ]
    }
   ],
   "source": [
    "# ###############################################################################################################################\n",
    "# ## Prepare data\n",
    "# #\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "import reader as dataset\n",
    "\n",
    "vocab, train_x, test_x, overall_maxlen = dataset.get_data(vocab_size=args.vocab_size, maxlen=args.maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = sequence.pad_sequences(train_x, maxlen=overall_maxlen)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=overall_maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:  580\n",
      "Length of vocab:  1661\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples: ', len(train_x))\n",
    "print('Length of vocab: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_batch_generator(data, batch_size):\n",
    "    n_batch = len(data) // batch_size\n",
    "    batch_count = 0\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    while True:\n",
    "        if batch_count >= n_batch:\n",
    "            np.random.shuffle(data)\n",
    "            batch_count = 0\n",
    "\n",
    "        batch = data[batch_count * batch_size: (batch_count + 1) * batch_size]\n",
    "        batch_count += 1\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_batch_generator(data, batch_size, neg_size):\n",
    "    data_len = data.shape[0]\n",
    "    dim = data.shape[1]\n",
    "\n",
    "    while True:\n",
    "        indices = np.random.choice(data_len, batch_size * neg_size)\n",
    "        samples = data[indices].reshape(batch_size, neg_size, dim)\n",
    "        yield samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer algorithm --------------------------------------------------------------------------------------------------\n",
    "\n",
    "from optimizers import get_optimizer\n",
    "\n",
    "optimizer = get_optimizer(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:17.802223  8168 textcleaner.py:37] 'pattern' package not found; tag filters are not available for English\n",
      "I0912 08:36:20.436011  8168 <ipython-input-22-a519dc19c43c>:6]   Building model\n"
     ]
    }
   ],
   "source": [
    "# Building model -------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from model import create_model\n",
    "import keras.backend as K\n",
    "\n",
    "logger.info('  Building model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_margin_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0912 08:36:34.536604  8168 deprecation_wrapper.py:119] From C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:529: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0912 08:36:34.543597  8168 deprecation_wrapper.py:119] From C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4420: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0912 08:36:34.583597  8168 deprecation_wrapper.py:119] From C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "I0912 08:36:34.768606  8168 w2v_emb_reader.py:22] Loading embeddings from: preprocessed_data/w2v_embedding\n",
      "I0912 08:36:34.769620  8168 utils.py:422] loading Word2Vec object from preprocessed_data/w2v_embedding\n",
      "I0912 08:36:34.774598  8168 utils.py:456] loading wv recursively from preprocessed_data/w2v_embedding.wv.* with mmap=None\n",
      "I0912 08:36:34.775601  8168 utils.py:494] setting ignored attribute vectors_norm to None\n",
      "I0912 08:36:34.776600  8168 utils.py:456] loading vocabulary recursively from preprocessed_data/w2v_embedding.vocabulary.* with mmap=None\n",
      "I0912 08:36:34.777599  8168 utils.py:456] loading trainables recursively from preprocessed_data/w2v_embedding.trainables.* with mmap=None\n",
      "I0912 08:36:34.778599  8168 utils.py:494] setting ignored attribute cum_table to None\n",
      "I0912 08:36:34.779599  8168 utils.py:428] loaded preprocessed_data/w2v_embedding\n",
      "I0912 08:36:34.790610  8168 w2v_emb_reader.py:39]   #vectors: 142, #dimensions: 200\n",
      "I0912 08:36:34.792603  8168 model.py:56] Initializing word embedding matrix\n",
      "W0912 08:36:34.793597  8168 deprecation_wrapper.py:119] From C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:178: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0912 08:36:34.794598  8168 deprecation_wrapper.py:119] From C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:185: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "I0912 08:36:35.260328  8168 w2v_emb_reader.py:59] 142/1661 word vectors initialized (hit rate: 8.55%)\n",
      "I0912 08:36:35.394276  8168 model.py:60] Initializing aspect embedding matrix as centroid of kmean clusters\n"
     ]
    }
   ],
   "source": [
    "model = create_model(args, overall_maxlen, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0912 08:36:35.543277  8168 deprecation_wrapper.py:119] From C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# freeze the word embedding layer\n",
    "model.get_layer('word_emb').trainable = False\n",
    "model.compile(optimizer=optimizer, loss=max_margin_loss, metrics=[max_margin_loss])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:36.538443  8168 <ipython-input-26-d7122f67df2c>:6] --------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "#\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger.info(\n",
    "    '--------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "vocab_inv = {}\n",
    "\n",
    "for w, ind in vocab.items():\n",
    "    vocab_inv[ind] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_gen = sentence_batch_generator(train_x, args.batch_size)\n",
    "neg_gen = negative_batch_generator(train_x, args.batch_size, args.neg_size)\n",
    "batches_per_epoch = len(train_x) // args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per epoch 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Batches per epoch\", batches_per_epoch)\n",
    "\n",
    "min_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]W0912 08:36:40.611649  8168 deprecation.py:323] From C:\\Users\\t15k\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:02<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['בזק : 0.9988861', 'ממשלה : 0.9988583', 'שאול : 0.9988226', \"אלוביץ' : 0.99881405\", 'שוחד : 0.9986738', 'ראש : 0.9986363', 'תיק : 0.9986132', 'נתניהו : 0.99860847', 'החלטה : 0.9984477', 'שליטה : 0.9984382', 'דין : 0.99842376', 'אביחי : 0.998381', 'בעל : 0.99837226', 'אישום : 0.99833715', 'יועץ : 0.99833244', 'הפרה : 0.99833226', 'מנדלבליט : 0.99830604', 'רשות : 0.9982872', 'משפטי : 0.99827975', 'כתב : 0.9982499']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:42.921411  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 0, train: 2s\n",
      "I0912 08:36:42.923413  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 19.5420, max_margin_loss: 19.5420, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 44.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['בזק : 0.998527', 'שאול : 0.9985069', \"אלוביץ' : 0.9984623\", 'ממשלה : 0.99837315', 'תיק : 0.9982135', 'נתניהו : 0.99819726', 'ראש : 0.9981855', 'שוחד : 0.9981682', 'הפרה : 0.99813384', 'אביחי : 0.99810433', 'דין : 0.99805117', 'משפטי : 0.99802876', 'שליטה : 0.99799806', 'החלטה : 0.99795294', 'בעל : 0.9979458', 'מנדלבליט : 0.9979377', 'יועץ : 0.99793017', 'אמון : 0.99792576', 'כתב : 0.99792075', 'רשות : 0.99782014']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:43.226412  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 1, train: 0s\n",
      "I0912 08:36:43.227415  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 19.0219, max_margin_loss: 19.0219, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 45.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['בזק : 0.99721307', 'שאול : 0.99720496', \"אלוביץ' : 0.99717736\", 'הפרה : 0.9970587', 'ממשלה : 0.9969907', 'ראש : 0.9969154', 'שוחד : 0.9968804', 'תיק : 0.99687994', 'משפטי : 0.99685603', 'דין : 0.9968424', 'אביחי : 0.99682057', 'נתניהו : 0.9968139', 'בעל : 0.99670684', 'שליטה : 0.99667364', 'עבירה : 0.99666655', 'אמון : 0.9966229', 'יועץ : 0.99661046', 'כתב : 0.9965756', 'מנדלבליט : 0.9965588', 'החלטה : 0.9965227']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:43.522413  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 2, train: 0s\n",
      "I0912 08:36:43.524414  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.8080, max_margin_loss: 18.8080, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 41.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['בזק : 0.9947703', 'הפרה : 0.9947541', 'שאול : 0.9947478', \"אלוביץ' : 0.99469376\", 'דין : 0.9944926', 'משפטי : 0.99448514', 'ראש : 0.99443185', 'עבירה : 0.9944041', 'ממשלה : 0.9943886', 'תיק : 0.99437606', 'שוחד : 0.9943743', 'אביחי : 0.99436057', 'נתניהו : 0.9942897', 'בעל : 0.99422526', 'יועץ : 0.99415714', 'אמון : 0.99413145', 'שליטה : 0.99412024', 'אתר : 0.9941151', 'כתב : 0.9940852', 'רעייה : 0.99407756']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:43.842415  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 3, train: 0s\n",
      "I0912 08:36:43.843418  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.7066, max_margin_loss: 18.7066, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 43.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['הפרה : 0.99201155', 'שאול : 0.99186563', 'בזק : 0.9918597', \"אלוביץ' : 0.99181044\", 'עבירה : 0.9917235', 'דין : 0.991686', 'משפטי : 0.9915878', 'אביחי : 0.9915201', 'תיק : 0.9914857', 'ראש : 0.991454', 'שוחד : 0.9914138', 'מקורב : 0.9913908', 'ממשלה : 0.991365', 'בעל : 0.9913178', 'נתניהו : 0.99131036', 'אלוביץ : 0.9912811', 'כתב : 0.9912051', 'אתר : 0.991202', 'אמון : 0.9911798', 'יועץ : 0.9911753']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:44.151419  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 4, train: 0s\n",
      "I0912 08:36:44.153418  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.7025, max_margin_loss: 18.7025, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 40.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['הפרה : 0.98904264', 'שאול : 0.98880184', \"אלוביץ' : 0.9887486\", 'בזק : 0.98873115', 'דין : 0.9886989', 'עבירה : 0.9886593', 'משפטי : 0.98857343', 'אלוביץ : 0.9885079', 'אביחי : 0.9883928', 'תיק : 0.9883833', 'מקורב : 0.9883752', 'ראש : 0.98836756', 'שוחד : 0.9882912', 'בעל : 0.9882065', 'ממשלה : 0.9881955', 'אתר : 0.9881458', 'נתניהו : 0.98813695', 'יועץ : 0.9880868', 'כתב : 0.98805004', 'שליטה : 0.98801595']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:44.477418  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 5, train: 0s\n",
      "I0912 08:36:44.478419  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.6502, max_margin_loss: 18.6502, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 42.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['הפרה : 0.9860348', 'שאול : 0.98570335', 'דין : 0.9856632', 'עבירה : 0.98565996', 'אלוביץ : 0.98562646', \"אלוביץ' : 0.9856023\", 'בזק : 0.98555815', 'משפטי : 0.9854498', 'מקורב : 0.98529744', 'אביחי : 0.98529327', 'תיק : 0.9852782', 'ראש : 0.98523843', 'שוחד : 0.9851358', 'בעל : 0.9851303', 'ממשלה : 0.9849849', 'יועץ : 0.9849767', 'אתר : 0.98493874', 'נתניהו : 0.98493755', 'כתב : 0.9848842', 'יחסים : 0.9848811']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:44.793423  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 6, train: 0s\n",
      "I0912 08:36:44.795423  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.5702, max_margin_loss: 18.5702, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 44.00it/s]\n",
      "I0912 08:36:45.055425  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 7, train: 0s\n",
      "I0912 08:36:45.056425  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.5847, max_margin_loss: 18.5847, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 45.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['הפרה : 0.98175037', 'אלוביץ : 0.98169285', 'עבירה : 0.9813789', 'דין : 0.9812925', 'שאול : 0.9812818', \"אלוביץ' : 0.9811964\", 'בזק : 0.98115444', 'משפטי : 0.9811202', 'אביחי : 0.9808657', 'ראש : 0.9808337', 'מקורב : 0.9807972', 'תיק : 0.9807871', 'שוחד : 0.9807525', 'אתר : 0.9806685', 'יועץ : 0.98064834', 'בעל : 0.9806316', 'יחסים : 0.98061234', 'הימין : 0.98056376', 'ממשלה : 0.98043394', 'נתניהו : 0.98040956']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:45.346423  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 8, train: 0s\n",
      "I0912 08:36:45.347424  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.5309, max_margin_loss: 18.5309, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 42.31it/s]\n",
      "I0912 08:36:45.612425  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 9, train: 0s\n",
      "I0912 08:36:45.614427  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.5721, max_margin_loss: 18.5721, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 43.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['אלוביץ : 0.9786866', 'הפרה : 0.9785516', 'עבירה : 0.97819847', 'דין : 0.97805583', \"אלוביץ' : 0.9779986\", 'משפטי : 0.9779612', 'שאול : 0.9779428', 'בזק : 0.97786874', 'מקורב : 0.9775635', 'אביחי : 0.9775218', 'ראש : 0.9775014', 'שוחד : 0.9775002', 'אתר : 0.9774548', 'תיק : 0.97742105', 'יועץ : 0.9773958', 'בעל : 0.9773333', 'יחסים : 0.9773217', 'הימין : 0.97727305', 'עניין : 0.9772569', 'שיחה : 0.9771797']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:45.925445  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 10, train: 0s\n",
      "I0912 08:36:45.926428  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4748, max_margin_loss: 18.4748, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 42.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect 0:\n",
      "['אלוביץ : 0.97757894', 'הפרה : 0.97753257', 'עבירה : 0.9770818', 'דין : 0.9769836', \"אלוביץ' : 0.9769039\", 'שאול : 0.97687566', 'משפטי : 0.97687197', 'בזק : 0.97669375', 'יחסים : 0.9764892', 'אביחי : 0.9764622', 'מקורב : 0.97641695', 'שוחד : 0.9763664', 'ראש : 0.97635144', 'אתר : 0.97633433', 'תיק : 0.9763096', 'בעל : 0.97623867', 'יועץ : 0.97623354', 'הימין : 0.97622806', 'עניין : 0.9761323', 'חוקר : 0.9761218']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0912 08:36:46.234426  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 11, train: 0s\n",
      "I0912 08:36:46.235427  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.3906, max_margin_loss: 18.3906, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 43.31it/s]\n",
      "I0912 08:36:46.496438  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 12, train: 0s\n",
      "I0912 08:36:46.497431  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.5045, max_margin_loss: 18.5045, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 49.11it/s]\n",
      "I0912 08:36:46.731434  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 13, train: 0s\n",
      "I0912 08:36:46.732434  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4573, max_margin_loss: 18.4573, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 40.00it/s]\n",
      "I0912 08:36:47.018434  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 14, train: 0s\n",
      "I0912 08:36:47.020435  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4788, max_margin_loss: 18.4788, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 42.47it/s]\n",
      "I0912 08:36:47.286434  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 15, train: 0s\n",
      "I0912 08:36:47.287445  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4477, max_margin_loss: 18.4477, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 46.02it/s]\n",
      "I0912 08:36:47.533437  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 16, train: 0s\n",
      "I0912 08:36:47.535438  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4786, max_margin_loss: 18.4786, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 44.90it/s]\n",
      "I0912 08:36:47.786442  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 17, train: 0s\n",
      "I0912 08:36:47.788438  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4912, max_margin_loss: 18.4912, ortho_reg: -0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 48.25it/s]\n",
      "I0912 08:36:48.023439  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 18, train: 0s\n",
      "I0912 08:36:48.025440  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4404, max_margin_loss: 18.4404, ortho_reg: 0.0000\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 45.08it/s]\n",
      "I0912 08:36:48.274438  8168 <ipython-input-29-f8eef542f0f5>:46] Epoch 19, train: 0s\n",
      "I0912 08:36:48.276450  8168 <ipython-input-29-f8eef542f0f5>:48] Total loss: 18.4096, max_margin_loss: 18.4096, ortho_reg: 0.0000\n"
     ]
    }
   ],
   "source": [
    "#for ii in range(args.epochs):\n",
    "for ii in range(20):\n",
    "    t0 = time()\n",
    "    loss, max_margin_loss = 0., 0.\n",
    "\n",
    "    for b in tqdm(range(batches_per_epoch)):\n",
    "        sen_input = next(sen_gen)\n",
    "        neg_input = next(neg_gen)\n",
    "\n",
    "        try:\n",
    "            batch_loss, batch_max_margin_loss = model.train_on_batch([sen_input, neg_input], np.ones((args.batch_size, 1)))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(sen_input.shape, sen_input)\n",
    "            print(neg_input.shape, neg_input)\n",
    "\n",
    "            print()\n",
    "            quit()\n",
    "\n",
    "        loss += batch_loss / batches_per_epoch\n",
    "        max_margin_loss += batch_max_margin_loss / batches_per_epoch\n",
    "\n",
    "    tr_time = time() - t0\n",
    "\n",
    "    if loss < min_loss:\n",
    "\n",
    "        min_loss = loss\n",
    "        word_emb = K.get_value(model.get_layer('word_emb').embeddings)\n",
    "        aspect_emb = K.get_value(model.get_layer('aspect_emb').W)\n",
    "        word_emb = word_emb / np.linalg.norm(word_emb, axis=-1, keepdims=True)\n",
    "        aspect_emb = aspect_emb / np.linalg.norm(aspect_emb, axis=-1, keepdims=True)\n",
    "        aspect_file = codecs.open(out_dir + '/aspect.log', 'w', 'utf-8')\n",
    "        model.save_weights(out_dir + '/model_param')\n",
    "\n",
    "        for ind in range(len(aspect_emb)):\n",
    "            desc = aspect_emb[ind]\n",
    "            sims = word_emb.dot(desc.T)\n",
    "            ordered_words = np.argsort(sims)[::-1]\n",
    "            desc_list = [vocab_inv[w] + \" : \" + str(sims[w]) for w in ordered_words[:20]]\n",
    "            desc_list_words = [vocab_inv[w] for w in ordered_words[:20]]\n",
    "            print('Aspect %d:' % ind)\n",
    "            print(desc_list)\n",
    "            aspect_file.write('Aspect %d:\\n' % ind)\n",
    "            aspect_file.write(' '.join(desc_list) + '\\n\\n')\n",
    "\n",
    "    logger.info('Epoch %d, train: %is' % (ii, tr_time))\n",
    "    logger.info(\n",
    "        'Total loss: %.4f, max_margin_loss: %.4f, ortho_reg: %.4f' % (loss, max_margin_loss, loss - max_margin_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "אלוביץ \n",
      "הפרה \n",
      "עבירה \n",
      "דין \n",
      "אלוביץ' \n",
      "שאול \n",
      "משפטי \n",
      "בזק \n",
      "יחסים \n",
      "אביחי \n",
      "מקורב \n",
      "שוחד \n",
      "ראש \n",
      "אתר \n",
      "תיק \n",
      "בעל \n",
      "יועץ \n",
      "הימין \n",
      "עניין \n",
      "חוקר \n"
     ]
    }
   ],
   "source": [
    "list_aspects=''\n",
    "for v in desc_list:\n",
    "    print(v.split(':')[0])\n",
    "    list_aspects+=v.split(':')[0]+','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"אלוביץ ,הפרה ,עבירה ,דין ,אלוביץ' ,שאול ,משפטי ,בזק ,יחסים ,אביחי ,מקורב ,שוחד ,ראש ,אתר ,תיק ,בעל ,יועץ ,הימין ,עניין ,חוקר ,\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
